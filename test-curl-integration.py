#!/usr/bin/env python3
"""
Simple test to verify curl_cffi integration is working
"""
import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'backend', 'core'))

def test_curl_cffi_import():
    """Test curl_cffi import and basic functionality"""
    print("ğŸ§ª Testing curl_cffi Integration")
    print("=" * 50)
    
    try:
        # Test curl_cffi import
        from curl_cffi import requests
        print("âœ… curl_cffi imported successfully")
        
        # Test browser impersonation
        browsers = ['chrome110', 'firefox109', 'safari15_3']
        print(f"âœ… Available browser impersonations: {len(browsers)}")
        
        # Test a simple request
        print("ğŸ”„ Testing simple HTTP request...")
        session = requests.Session(impersonate='chrome110')
        
        # Test with a simple endpoint that doesn't block
        response = session.get('https://httpbin.org/headers', timeout=10)
        if response.status_code == 200:
            print("âœ… Basic HTTP request successful")
            print(f"   Status: {response.status_code}")
            # Check if headers look like Chrome
            headers = response.json().get('headers', {})
            user_agent = headers.get('User-Agent', '')
            if 'Chrome' in user_agent:
                print(f"âœ… Browser impersonation working (Chrome detected)")
            else:
                print(f"âš ï¸  User-Agent: {user_agent}")
        else:
            print(f"âŒ Request failed with status {response.status_code}")
        
        session.close()
        return True
        
    except Exception as e:
        print(f"âŒ curl_cffi test failed: {e}")
        return False

def test_scraper_integration():
    """Test curl_cffi scraper integration with the main system"""
    print("\nğŸ”§ Testing Scraper Integration")
    print("=" * 50)
    
    try:
        # Test importing the scraper class
        from curl_cffi_scraper import CurlCffiScraper, CURL_CFFI_AVAILABLE
        print(f"âœ… CurlCffiScraper import: {'Success' if CURL_CFFI_AVAILABLE else 'Failed'}")
        
        if not CURL_CFFI_AVAILABLE:
            print("âŒ curl_cffi not available for scraper")
            return False
        
        # Mock config for testing
        class MockConfig:
            def get(self, key, default=None):
                config_values = {
                    'enrichment.enable_curl_cffi': True,
                    'enrichment.website_scrape_timeout': 15,
                    'enrichment.curl_cffi_max_retries': 2
                }
                return config_values.get(key, default)
        
        class MockProxyManager:
            def get_requests_proxy_dict(self):
                return None  # No proxy for testing
        
        # Test scraper initialization
        scraper = CurlCffiScraper(MockConfig(), MockProxyManager())
        print(f"âœ… Scraper initialized: {'Enabled' if scraper.enabled else 'Disabled'}")
        print(f"   Browser versions: {len(scraper.browser_versions)}")
        print(f"   Max retries: {scraper.max_retries}")
        print(f"   Timeout: {scraper.timeout}s")
        
        # Test session management
        with scraper.get_session('test.com') as session:
            print("âœ… Session context manager working")
        
        scraper.cleanup()
        print("âœ… Cleanup successful")
        
        return True
        
    except Exception as e:
        print(f"âŒ Scraper integration test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_enricher_integration():
    """Test integration with enricher"""
    print("\nğŸ”— Testing Enricher Integration")
    print("=" * 50)
    
    try:
        from main import initialize_components
        import main as core
        
        if not initialize_components():
            print("âŒ Failed to initialize components")
            return False
        
        print("âœ… Components initialized successfully")
        
        # Check enricher configuration
        enricher = core.enricher
        print(f"âœ… Enricher curl_cffi enabled: {enricher.use_curl_cffi}")
        
        if hasattr(enricher, 'curl_cffi_scraper') and enricher.curl_cffi_scraper:
            print("âœ… curl_cffi_scraper instance created")
            print(f"   Scraper enabled: {enricher.curl_cffi_scraper.enabled}")
        else:
            print("âŒ No curl_cffi_scraper instance")
            return False
        
        return True
        
    except Exception as e:
        print(f"âŒ Enricher integration test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    print("ğŸš€ curl_cffi Integration Test Suite")
    print("=" * 50)
    
    tests = [
        ("curl_cffi Import", test_curl_cffi_import),
        ("Scraper Integration", test_scraper_integration), 
        ("Enricher Integration", test_enricher_integration)
    ]
    
    results = []
    for name, test_func in tests:
        print(f"\nğŸ“‹ Running: {name}")
        try:
            result = test_func()
            results.append((name, result))
        except Exception as e:
            print(f"âŒ Test {name} crashed: {e}")
            results.append((name, False))
    
    print("\nğŸ“Š TEST RESULTS")
    print("=" * 50)
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for name, result in results:
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"{status}: {name}")
    
    print(f"\nğŸ¯ Summary: {passed}/{total} tests passed")
    
    if passed == total:
        print("ğŸ‰ All integration tests successful!")
        print("ğŸ”§ curl_cffi is properly integrated and ready for enhanced email discovery")
    else:
        print("âš ï¸  Some tests failed - check the output above for details")

if __name__ == "__main__":
    main()